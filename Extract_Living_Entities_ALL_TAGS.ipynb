{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extract_Living_Entities.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya-Jbwt-26_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ea0a8c-3746-43c9-dd87-e32a0db53ac6"
      },
      "source": [
        "!pip install gast==0.2.2\n",
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow_hub>=0.6.0\n",
        "!pip3 install tensorflow_text==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=9184276f3589572aee8dbdba2e1d7920f28a61075b504eaba56e8d4f7896530a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (56.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting tensorflow_text==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/93/cfa6d4532d9cb7707028d7d4fd505fa7aab9d6e08275322e516bf6de509d/tensorflow_text-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.36.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (56.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqda9l4__Ide",
        "outputId": "1928facd-1892-40f0-c994-270fe045d66e"
      },
      "source": [
        "!pip3 install seqeval"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 27.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=a0ac75cd358cab8ba9885f185bc2f98619cc8e7e79c77c0d82e663fca53accd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t44DGe64B69"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtaHA9iy4H_K"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dSgpK9g4PJT"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1j8_XsnH3IhqoBXGm6S9aP7Aa_D4aqXbz\"})   \n",
        "downloaded.GetContentFile('chap4_mahabharath_annotations.csv') "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zMBBgrH28Bm"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdPnxzl-26_y"
      },
      "source": [
        "import pandas as pd\n",
        "annotations = pd.read_csv(\"chap4_mahabharath_annotations.csv\", index_col=['id'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqSEeZwfBRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "30f68c70-0d1a-4201-b88b-56d83e5a2463"
      },
      "source": [
        "annotations"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence#</th>\n",
              "      <th>token</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Om</td>\n",
              "      <td>CONCEPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>!</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Having</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>bowed</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>down</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830510</th>\n",
              "      <td>34331</td>\n",
              "      <td>The</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830511</th>\n",
              "      <td>34331</td>\n",
              "      <td>end</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830512</th>\n",
              "      <td>34331</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830513</th>\n",
              "      <td>34331</td>\n",
              "      <td>Virata</td>\n",
              "      <td>BOOK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830514</th>\n",
              "      <td>34331</td>\n",
              "      <td>Parva</td>\n",
              "      <td>BOOK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>830515 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentence#   token      tag\n",
              "id                                \n",
              "0               0      Om  CONCEPT\n",
              "1               0       !        O\n",
              "2               1  Having        O\n",
              "3               1   bowed        O\n",
              "4               1    down        O\n",
              "...           ...     ...      ...\n",
              "830510      34331     The        O\n",
              "830511      34331     end        O\n",
              "830512      34331      of        O\n",
              "830513      34331  Virata     BOOK\n",
              "830514      34331   Parva     BOOK\n",
              "\n",
              "[830515 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc2lv0E9fmDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c239497-65e4-4e27-8cfe-01825d18d3cd"
      },
      "source": [
        "words = list(annotations['token'].values)\n",
        "words.append('PADword')\n",
        "n_words = len(set(words))\n",
        "n_words, len(words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19573, 830516)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3rLIjhLfp3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed3d86c-2dd6-4026-ea24-1d5cb6928662"
      },
      "source": [
        "tags = list(set(annotations[\"tag\"].values))\n",
        "n_tags = len(tags)\n",
        "print(n_tags)\n",
        "tags"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WATER',\n",
              " 'PLANT',\n",
              " 'CONCEPT',\n",
              " 'WEAPON',\n",
              " 'SPECIAL_OBJECT',\n",
              " 'TITLE',\n",
              " 'BOOK',\n",
              " 'PLACE',\n",
              " 'GROUP',\n",
              " 'PERSON',\n",
              " 'O',\n",
              " 'ANIMAL']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz_TCPfFfr0y"
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 0\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"token\"].values.tolist(),s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"sentence#\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[self.n_sent]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZteC_p2fr4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ee650c-827a-4062-bc5f-a837abfe4ef1"
      },
      "source": [
        "getter = SentenceGetter(annotations)\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Om', 'CONCEPT'), ('!', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwNXe6usfr_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a270ab-7e11-40a5-8599-10e8940d37b7"
      },
      "source": [
        "sentences = getter.sentences\n",
        "print(len(sentences))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw79xauvfsDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccb6e66-df68-4dce-871e-8a7d6471dd44"
      },
      "source": [
        "largest_sen = max(len(sen) for sen in sentences)\n",
        "print('biggest sentence has {} words'.format(largest_sen))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "biggest sentence has 428 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB4viWJLfsII",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "83e8e64c-4930-4a02-ce1a-ecd5b4d077a7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "plt.hist([len(s) for s in sentences], bins = 50)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC2wY8tgfsOD"
      },
      "source": [
        "max_len = 50\n",
        "X = [[w[0] for w in s] for s in sentences]\n",
        "Y = [[w[1] for w in s] for s in sentences]\n",
        "new_X = []\n",
        "y_label = []\n",
        "for k in range(len(X)):\n",
        "    seq = X[k]\n",
        "    j = 0\n",
        "    while(j<len(seq)):\n",
        "        new_seq = []\n",
        "        new_y = []\n",
        "        for i in range(j,j+max_len):\n",
        "            try:\n",
        "                new_seq.append(seq[i])\n",
        "                new_y.append(Y[k][i])\n",
        "            except:\n",
        "                new_seq.append(\"PADword\")\n",
        "                new_y.append('O')\n",
        "        new_X.append(new_seq)\n",
        "        y_label.append(new_y)\n",
        "        j=i+1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoZehxXhfsRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a5d53f-5628-487e-89b3-1c2855eb2770"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "living_entity_tags = ['ANIMAL','PERSON','GROUP','TITLE']\n",
        "non_living_entity_tags = ['BOOK','PLACE','WEAPON','SPECIAL_OBJECT','PLANT','CONCEPT','WATER']\n",
        "\n",
        "#for extraction of entities\n",
        "# tags2index = {}\n",
        "# for tag in tags:\n",
        "#     if tag not in living_entity_tags:\n",
        "#         tags2index[tag] = 0\n",
        "#     else:\n",
        "#         tags2index[tag] = 1\n",
        "        \n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "y=[]        \n",
        "for labels in y_label:\n",
        "    word_tag = []\n",
        "    for label in labels:\n",
        "#         print(label)\n",
        "        word_tag.append(tags2index[label])\n",
        "    y.append(np.array(word_tag))\n",
        "tags2index"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ANIMAL': 11,\n",
              " 'BOOK': 6,\n",
              " 'CONCEPT': 2,\n",
              " 'GROUP': 8,\n",
              " 'O': 10,\n",
              " 'PERSON': 9,\n",
              " 'PLACE': 7,\n",
              " 'PLANT': 1,\n",
              " 'SPECIAL_OBJECT': 4,\n",
              " 'TITLE': 5,\n",
              " 'WATER': 0,\n",
              " 'WEAPON': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoTCJPBrW_mZ"
      },
      "source": [
        "y = np.array(y)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOGRqoU1Vxmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8448045a-f747-4c2a-8b8a-83d8ec9d6ffb"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOFrmis_f6s7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import add, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "import seqeval\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "batch_size = 32\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x,tf.string)),\n",
        "                              \"sequence_len\": tf.constant(batch_size*[max_len])},\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.1, random_state=2021)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e28NDkDf6w9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "K.set_session(sess)\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbY02KoZf65B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c228b1-58e8-49ca-ba84-03b4940cd10a"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "\n",
        "\n",
        "\n",
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2) )(x)\n",
        "x = add([x, x_rnn])  \n",
        "out = TimeDistributed(Dense(12, activation=\"softmax\"))(x)\n",
        "# out = TimeDistributed(Dense(2, activation=\"softmax\"))(x)\n",
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnoPfIR26_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e2548e-ed18-4cc2-89e6-d51b6e9b9c0f"
      },
      "source": [
        "len(X_tr), len(X_te), batch_size,len(X_tr)/batch_size, len(X_te)/batch_size "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32470, 3608, 32, 1014.6875, 112.75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWGprhItf69Z"
      },
      "source": [
        "X_tr, X_val = X_tr[:914*batch_size], X_tr[-100*batch_size:]\n",
        "y_tr, y_val = y_tr[:914*batch_size], y_tr[-100*batch_size:]\n",
        "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
        "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxvfqnJnpy4e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce165015-4168-4333-fac4-1fc473c940a4"
      },
      "source": [
        "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),batch_size=batch_size, epochs=3, verbose=1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29248 samples, validate on 3200 samples\n",
            "Epoch 1/3\n",
            "29248/29248 [==============================] - 447s 15ms/sample - loss: 0.0169 - acc: 0.9955 - val_loss: 0.0069 - val_acc: 0.9981\n",
            "Epoch 2/3\n",
            "29248/29248 [==============================] - 448s 15ms/sample - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0060 - val_acc: 0.9984\n",
            "Epoch 3/3\n",
            "29248/29248 [==============================] - 447s 15ms/sample - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0054 - val_acc: 0.9982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dz5U9Fnf7Cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60dcfdca-dc0b-4cb0-f02f-4b0e4828d3a6"
      },
      "source": [
        "X_te = X_te[:112*batch_size]\n",
        "y_te = y_te[:112*batch_size]\n",
        "preds = model.predict(np.array(X_te), verbose=1, batch_size=batch_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3584/3584 [==============================] - 33s 9ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrZ9lf_af7Gz"
      },
      "source": [
        "# in case of classification\n",
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "# in case of extraction of entities\n",
        "# idx2tag = {}\n",
        "# for k,v in tags2index.items():\n",
        "#     if v == 0:\n",
        "#         idx2tag[v] = 'O'\n",
        "#     else:\n",
        "#         idx2tag[v] = \"ENTITY\"\n",
        "        \n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gRinCi526_5"
      },
      "source": [
        "pred_labels = pred2label(preds)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrQenJ0y26_5"
      },
      "source": [
        "test_labels = test2label(y_te)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooHmfrEP26_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c8e1b7-5e0e-4ea9-c8e0-a462dc4161f6"
      },
      "source": [
        "print(classification_report(pred_labels, test_labels))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PERSON seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANIMAL seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: BOOK seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: GROUP seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: TITLE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CONCEPT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WATER seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PLACE seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PLANT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SPECIAL_OBJECT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: WEAPON seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ATER       0.74      0.91      0.81        53\n",
            "        EAPON       0.50      1.00      0.67        14\n",
            "        ERSON       0.98      0.93      0.96      3004\n",
            "         ITLE       0.91      0.98      0.95       300\n",
            "         LACE       0.78      0.81      0.79       165\n",
            "         LANT       0.59      0.52      0.55        25\n",
            "        NIMAL       0.22      0.49      0.30        43\n",
            "       ONCEPT       0.86      0.73      0.79       177\n",
            "          OOK       0.88      0.98      0.93       194\n",
            "PECIAL_OBJECT       0.36      0.87      0.51        15\n",
            "         ROUP       0.95      0.98      0.97       592\n",
            "\n",
            "    micro avg       0.93      0.93      0.93      4582\n",
            "    macro avg       0.71      0.84      0.75      4582\n",
            " weighted avg       0.94      0.93      0.93      4582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aR2xv96SoCc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}