{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ya-Jbwt-26_q",
    "outputId": "5ca660f2-77b7-4ef0-a861-61150bfaf874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=9651c655b165ab3899593ae8879a4594d519fb0fe4307f78d492aa2361381460\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "Successfully installed gast-0.2.2\n",
      "Collecting tensorflow==1.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
      "\u001b[K     |████████████████████████████████| 412.3MB 27kB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 29.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 34.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (56.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
      "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
      "Collecting tensorflow_text==1.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/93/cfa6d4532d9cb7707028d7d4fd505fa7aab9d6e08275322e516bf6de509d/tensorflow_text-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (9.1MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1MB 4.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.19.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.36.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.12.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.32.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (56.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.1)\n",
      "Installing collected packages: tensorflow-text\n",
      "Successfully installed tensorflow-text-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gast==0.2.2\n",
    "!pip install tensorflow==1.15\n",
    "!pip install tensorflow_hub>=0.6.0\n",
    "!pip3 install tensorflow_text==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vqda9l4__Ide",
    "outputId": "9364e7b2-cfae-4f3c-d7ad-74932098ecc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "\r",
      "\u001b[K     |███████▌                        | 10kB 12.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 20kB 11.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 30kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 40kB 7.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=db077d32b9156d79c5e478adb321e5debc868937a6cb96be5405a503d8175d9d\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6t44DGe64B69"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gtaHA9iy4H_K"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8dSgpK9g4PJT"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':\"1j8_XsnH3IhqoBXGm6S9aP7Aa_D4aqXbz\"})   \n",
    "downloaded.GetContentFile('chap4_mahabharath_annotations.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zMBBgrH28Bm"
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tdPnxzl-26_y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "annotations = pd.read_csv(\"chap4_mahabharath_annotations.csv\", index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "laqSEeZwfBRt",
    "outputId": "8deec283-c819-4eb1-e121-ba639a750f9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence#</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Om</td>\n",
       "      <td>CONCEPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>!</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Having</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bowed</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>down</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830510</th>\n",
       "      <td>34331</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830511</th>\n",
       "      <td>34331</td>\n",
       "      <td>end</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830512</th>\n",
       "      <td>34331</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830513</th>\n",
       "      <td>34331</td>\n",
       "      <td>Virata</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830514</th>\n",
       "      <td>34331</td>\n",
       "      <td>Parva</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence#   token      tag\n",
       "id                                \n",
       "0               0      Om  CONCEPT\n",
       "1               0       !        O\n",
       "2               1  Having        O\n",
       "3               1   bowed        O\n",
       "4               1    down        O\n",
       "...           ...     ...      ...\n",
       "830510      34331     The        O\n",
       "830511      34331     end        O\n",
       "830512      34331      of        O\n",
       "830513      34331  Virata     BOOK\n",
       "830514      34331   Parva     BOOK\n",
       "\n",
       "[830515 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc2lv0E9fmDm",
    "outputId": "709e4d31-7729-48dc-dbcd-4062b96db57b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19573, 830516)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(annotations['token'].values)\n",
    "words.append('PADword')\n",
    "n_words = len(set(words))\n",
    "n_words, len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3rLIjhLfp3N",
    "outputId": "20bf7ca4-8ec4-432d-ad5e-b094b5a3bbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WATER',\n",
       " 'PERSON',\n",
       " 'O',\n",
       " 'TITLE',\n",
       " 'GROUP',\n",
       " 'CONCEPT',\n",
       " 'BOOK',\n",
       " 'WEAPON',\n",
       " 'PLANT',\n",
       " 'SPECIAL_OBJECT',\n",
       " 'PLACE',\n",
       " 'ANIMAL']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(annotations[\"tag\"].values))\n",
    "n_tags = len(tags)\n",
    "print(n_tags)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hz_TCPfFfr0y"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 0\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"token\"].values.tolist(),s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence#\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZteC_p2fr4h",
    "outputId": "494681f1-9647-4079-a1f1-f8d6819a9a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Om', 'CONCEPT'), ('!', 'O')]\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(annotations)\n",
    "sent = getter.get_next()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwNXe6usfr_N",
    "outputId": "71d33e30-f5da-4e50-acef-0948d48b087d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34332\n"
     ]
    }
   ],
   "source": [
    "sentences = getter.sentences\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cw79xauvfsDR",
    "outputId": "00603686-f421-47a7-beca-fb9e99557f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biggest sentence has 428 words\n"
     ]
    }
   ],
   "source": [
    "largest_sen = max(len(sen) for sen in sentences)\n",
    "print('biggest sentence has {} words'.format(largest_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "LB4viWJLfsII",
    "outputId": "81feeb5e-750e-4adb-ac88-9bdcdbb8f948"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "plt.hist([len(s) for s in sentences], bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xC2wY8tgfsOD"
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X = [[w[0] for w in s] for s in sentences]\n",
    "Y = [[w[1] for w in s] for s in sentences]\n",
    "new_X = []\n",
    "y_label = []\n",
    "for k in range(len(X)):\n",
    "    seq = X[k]\n",
    "    j = 0\n",
    "    while(j<len(seq)):\n",
    "        new_seq = []\n",
    "        new_y = []\n",
    "        for i in range(j,j+max_len):\n",
    "            try:\n",
    "                new_seq.append(seq[i])\n",
    "                new_y.append(Y[k][i])\n",
    "            except:\n",
    "                new_seq.append(\"PADword\")\n",
    "                new_y.append('O')\n",
    "        new_X.append(new_seq)\n",
    "        y_label.append(new_y)\n",
    "        j=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoZehxXhfsRx",
    "outputId": "6edb4300-1dbf-4b4a-d87c-4a7cb46401ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANIMAL': 1,\n",
       " 'BOOK': 2,\n",
       " 'CONCEPT': 2,\n",
       " 'GROUP': 1,\n",
       " 'O': 0,\n",
       " 'PERSON': 1,\n",
       " 'PLACE': 2,\n",
       " 'PLANT': 2,\n",
       " 'SPECIAL_OBJECT': 2,\n",
       " 'TITLE': 1,\n",
       " 'WATER': 2,\n",
       " 'WEAPON': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "living_entity_tags = ['ANIMAL','PERSON','GROUP','TITLE']\n",
    "non_living_entity_tags = ['BOOK','PLACE','WEAPON','SPECIAL_OBJECT','PLANT','CONCEPT','WATER']\n",
    "\n",
    "#for extraction of entities\n",
    "tags2index = {}\n",
    "for tag in tags:\n",
    "    if tag not in living_entity_tags and tag not in non_living_entity_tags:\n",
    "        tags2index[tag] = 0\n",
    "    elif tag in living_entity_tags:\n",
    "        tags2index[tag] = 1\n",
    "    else:\n",
    "        tags2index[tag] = 2\n",
    "        \n",
    "# tags2index = {t:i for i,t in enumerate(tags)}\n",
    "y=[]        \n",
    "for labels in y_label:\n",
    "    word_tag = []\n",
    "    for label in labels:\n",
    "#         print(label)\n",
    "        word_tag.append(tags2index[label])\n",
    "    y.append(np.array(word_tag))\n",
    "tags2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CoTCJPBrW_mZ"
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOGRqoU1Vxmg",
    "outputId": "f7124e29-4af8-4841-9254-409672e02bd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]),\n",
       " ['Om',\n",
       "  '!',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword',\n",
       "  'PADword'])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], new_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cOFrmis_f6s7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import add, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "import seqeval\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "batch_size = 32\n",
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x,tf.string)),\n",
    "                              \"sequence_len\": tf.constant(batch_size*[max_len])},\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.1, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7e28NDkDf6w9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "K.set_session(sess)\n",
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbY02KoZf65B",
    "outputId": "f3ff8f0a-ca3b-4d4a-8a1d-9f6aa0c54b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "\n",
    "\n",
    "\n",
    "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
    "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
    "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2) )(x)\n",
    "x = add([x, x_rnn])  \n",
    "# out = TimeDistributed(Dense(12, activation=\"softmax\"))(x)\n",
    "out = TimeDistributed(Dense(3, activation=\"softmax\"))(x)\n",
    "model = Model(input_text, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZnoPfIR26_3",
    "outputId": "a5b08273-0d98-42c5-8438-f2faaaed51f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32470, 3608, 32, 1014.6875, 112.75)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tr), len(X_te), batch_size,len(X_tr)/batch_size, len(X_te)/batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZWGprhItf69Z"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val = X_tr[:914*batch_size], X_tr[-100*batch_size:]\n",
    "y_tr, y_val = y_tr[:914*batch_size], y_tr[-100*batch_size:]\n",
    "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxvfqnJnpy4e",
    "outputId": "a2967691-5549-4e4a-fb15-0fe3dd3ff92c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29248 samples, validate on 3200 samples\n",
      "Epoch 1/3\n",
      "29248/29248 [==============================] - 1125s 38ms/sample - loss: 0.0095 - acc: 0.9966 - val_loss: 0.0035 - val_acc: 0.9989\n",
      "Epoch 2/3\n",
      "29248/29248 [==============================] - 1119s 38ms/sample - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0044 - val_acc: 0.9985\n",
      "Epoch 3/3\n",
      "29248/29248 [==============================] - 1117s 38ms/sample - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0029 - val_acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),batch_size=batch_size, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dz5U9Fnf7Cl",
    "outputId": "07b98a19-b9e4-456e-dc48-ecfad49b0b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584/3584 [==============================] - 86s 24ms/sample\n"
     ]
    }
   ],
   "source": [
    "X_te = X_te[:112*batch_size]\n",
    "y_te = y_te[:112*batch_size]\n",
    "preds = model.predict(np.array(X_te), verbose=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NrZ9lf_af7Gz"
   },
   "outputs": [],
   "source": [
    "# in case of classification\n",
    "# idx2tag = {i: w for w, i in tags2index.items()}\n",
    "\n",
    "# in case of extraction of entities\n",
    "idx2tag = {}\n",
    "for k,v in tags2index.items():\n",
    "    if v == 0:\n",
    "        idx2tag[v] = 'O'\n",
    "    elif v == 1:\n",
    "        idx2tag[v] = \"LIVING\"\n",
    "    else:\n",
    "      idx2tag[v] = \"NON-LIVING\"\n",
    "        \n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "def test2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2gRinCi526_5"
   },
   "outputs": [],
   "source": [
    "pred_labels = pred2label(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WrQenJ0y26_5"
   },
   "outputs": [],
   "source": [
    "test_labels = test2label(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooHmfrEP26_6",
    "outputId": "46be6fcc-d636-4874-bdf9-1b24b60cd2e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LIVING seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NON-LIVING seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IVING       0.99      0.96      0.98      3955\n",
      "      LIVING       0.76      0.86      0.81       545\n",
      "\n",
      "   micro avg       0.96      0.95      0.95      4500\n",
      "   macro avg       0.87      0.91      0.89      4500\n",
      "weighted avg       0.96      0.95      0.96      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_labels, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aR2xv96SoCc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Extract_Living_Entities.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
