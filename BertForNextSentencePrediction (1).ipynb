{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvxqzflOc4vG",
    "outputId": "ab886e23-d00e-4ac8-c80e-568543ed45d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/anaconda3/lib/python3.7/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.7/site-packages (from torch) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQPBFFiFc7Tk",
    "outputId": "7c0e964f-c120-46fb-e554-9f476ab7fc1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/shreya15096/.local/lib/python3.7/site-packages (4.9.0.dev0)\n",
      "Requirement already satisfied: sacremoses in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (19.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (5.1.2)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (1.17.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (0.23)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (4.36.1)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: typing-extensions in /home/shreya15096/.local/lib/python3.7/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: more-itertools in /usr/local/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->transformers) (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dhUCkjk1c9s0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pKkF_O-DeCZi"
   },
   "outputs": [],
   "source": [
    " with open('mahabharath_4chapters_combined.txt','r') as f:\n",
    "    text = f.read().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zB1SueACr5wz"
   },
   "outputs": [],
   "source": [
    "text = [sent.replace('\\n',' ') for sent in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzGuFiLCsncP",
    "outputId": "438b38ed-0414-4c2e-b6c6-05bc2967c433"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Ugrasrava, the son of Lomaharshana, surnamed Sauti, well-versed in the Puranas, bending with humility, one day approached the great sages of rigid vows, sitting at their ease, who had attended the twelve years' sacrifice of Saunaka, surnamed Kulapati, in the forest of Naimisha\",\n",
       " ' Those ascetics, wishing to hear his wonderful narrations, presently began to address him who had thus arrived at that recluse abode of the inhabitants of the forest of Naimisha',\n",
       " ' Having been entertained with due respect by those holy men, he saluted those Munis (sages) with joined palms, even all of them, and inquired about the progress of their asceticism',\n",
       " ' Then all the ascetics being again seated, the son of Lomaharshana humbly occupied the seat that was assigned to him',\n",
       " \" Seeing that he was comfortably seated, and recovered from fatigue, one of the Rishis beginning the conversation, asked him, 'Whence comest thou, O lotus-eyed Sauti, and where hast thou spent the time? Tell me, who ask thee, in detail\",\n",
       " \"'\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5DaDu1g-rmzT"
   },
   "outputs": [],
   "source": [
    "bag = [sentence for para in text for sentence in para.split('.') if sentence != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3SQJL9GQtgkS"
   },
   "outputs": [],
   "source": [
    "bag_size = len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uECdfTpirmhr",
    "outputId": "50f135cb-fdc5-42ee-f4ee-c0b2141fc9f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32036"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Sunga9dnt5MY"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "for para in text:\n",
    "    sentences = [sentence for sentence in para.split('.') if sentence != '']\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        start = random.randint(0,num_sentences-2)\n",
    "        sentence_a.append(sentences[start])\n",
    "        if random.random() > 0.5:\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "        else:\n",
    "            sentence_b.append(bag[random.randint(0,bag_size-1)])\n",
    "            label.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4WNhiQewVec",
    "outputId": "67ff2816-f4d5-4a6f-e4c1-de9d1a3812d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxo99X58wiTY",
    "outputId": "2a85b4bb-19b6-4b99-8d7e-6fac12406825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " Those ascetics, wishing to hear his wonderful narrations, presently began to address him who had thus arrived at that recluse abode of the inhabitants of the forest of Naimisha\n",
      "----\n",
      " Having been entertained with due respect by those holy men, he saluted those Munis (sages) with joined palms, even all of them, and inquired about the progress of their asceticism\n",
      "\n",
      "0\n",
      "\"Sauti said, 'Having heard the diverse sacred and wonderful stories which were composed in his Mahabharata by Krishna-Dwaipayana, and which were recited in full by Vaisampayana at the Snake-sacrifice of the high-souled royal sage Janamejaya and in the presence also of that chief of Princes, the son of Parikshit, and having wandered about, visiting many sacred waters and holy shrines, I journeyed to the country venerated by the Dwijas (twice-born) and called Samantapanchaka where formerly was fought the battle between the children of Kuru and Pandu, and all the chiefs of the land ranged on either side\n",
      "----\n",
      " Thence, anxious to see you, I am come into your presence\n",
      "\n",
      "1\n",
      " Composed in elegant language, it includeth the subjects of other books\n",
      "----\n",
      " But when those brave Gandharvas, resorting to their many powers of illusion, ascended the skies and began to fight with us thence, our encounter with them ceased to be an equal one\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print(sentence_a[i] + '\\n----')\n",
    "    print(sentence_b[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /home/shreya15096/.local/lib/python3.7/site-packages (4.9.0.dev0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (5.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (4.36.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.23)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (19.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (1.17.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers[sentencepiece]) (2021.7.6)\n",
      "Requirement already satisfied: sacremoses in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.10.3)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /home/shreya15096/.local/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.0.12)\n",
      "Collecting sentencepiece==0.1.91; extra == \"sentencepiece\" (from transformers[sentencepiece])\n",
      "  Using cached https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: protobuf; extra == \"sentencepiece\" in /usr/local/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.11.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/anaconda3/lib/python3.7/site-packages (from packaging->transformers[sentencepiece]) (2.4.2)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/lib/python3.7/site-packages (from packaging->transformers[sentencepiece]) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers[sentencepiece]) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers[sentencepiece]) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions in /home/shreya15096/.local/lib/python3.7/site-packages (from huggingface-hub==0.0.12->transformers[sentencepiece]) (3.10.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/anaconda3/lib/python3.7/site-packages (from protobuf; extra == \"sentencepiece\"->transformers[sentencepiece]) (41.4.0)\n",
      "Requirement already satisfied: more-itertools in /usr/local/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (7.2.0)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.91\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user \"transformers[sentencepiece]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Version\n",
      "  Using cached https://files.pythonhosted.org/packages/fd/b6/fa3b2c859d4d8817a106e4272029d78a2afbca0a27139997a4e5515bbf60/version-0.1.1.tar.gz\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /usr/local/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_90x5mlj/Version/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_90x5mlj/Version/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base pip-egg-info\n",
      "         cwd: /tmp/pip-install-_90x5mlj/Version/\n",
      "    Complete output (7 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-_90x5mlj/Version/setup.py\", line 4, in <module>\n",
      "        from version import __version__\n",
      "      File \"/tmp/pip-install-_90x5mlj/Version/version.py\", line 2, in <module>\n",
      "        from itertools import izip_longest\n",
      "    ImportError: cannot import name 'izip_longest' from 'itertools' (unknown location)\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yd2kdZmkeCUA",
    "outputId": "e8e63073-19d0-4105-feac-ce9e7fa932af"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Version' object has no attribute 'major'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-50a0c5a6e380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForNextSentencePrediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForNextSentencePrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreya15096/.local/lib/python3.7/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m from .file_utils import (\n\u001b[1;32m     45\u001b[0m     \u001b[0m_LazyModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreya15096/.local/lib/python3.7/site-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreya15096/.local/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_torch_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mtorch_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     _torch_fx_available = (torch_version.major, torch_version.minor) == (\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mTORCH_FX_REQUIRED_VERSION\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mTORCH_FX_REQUIRED_VERSION\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Version' object has no attribute 'major'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh-b31YleCRg"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a,sentence_b,return_tensors = 'pt',max_length =512,truncation =True,padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZDAItIGeCO-",
    "outputId": "7541b2f7-8c89-410e-fef5-c09ca7f2d645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AefbO_XneCMO",
    "outputId": "e25a57e1-6ce9-44c6-b978-d4aa1c2e3968"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  3773,  2008,  2002,  2001, 18579,  8901,  1010,  1998,  6757,\n",
       "         2013, 16342,  1010,  2028,  1997,  1996, 15544,  6182,  2015,  2927,\n",
       "         1996,  4512,  1010,  2356,  2032,  1010,  1005,  2043,  3401,  3310,\n",
       "         2102, 15223,  1010,  1051, 13030,  1011,  7168,  7842, 21823,  1010,\n",
       "         1998,  2073,  2038,  2102, 15223,  2985,  1996,  2051,  1029,  2425,\n",
       "         2033,  1010,  2040,  3198, 14992,  1010,  1999,  6987,   102,  1005,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em1rtzBLeCJm"
   },
   "outputs": [],
   "source": [
    "inputs['labels'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oqc9q1KseCG3",
    "outputId": "f90e7ec6-ec01-4981-9219-95ba959efe18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcV0iMkP3B60"
   },
   "outputs": [],
   "source": [
    "class MahabharatDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,encodings):\n",
    "    self.encodings = encodings\n",
    "  def __getitem__(self,idx):\n",
    "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "  def __len__(self):\n",
    "    return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBYLO3pO-m2l"
   },
   "outputs": [],
   "source": [
    "dataset = MahabharatDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Cu989U5-wHI"
   },
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGXMQjy1_evR"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxFGC6w7_p3i"
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1iAYZwk_4GE"
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsoWERhCAAC0"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(),lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSZNO_2jAQ4L",
    "outputId": "f0078526-b727-4f92-d187-8ef599726e3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/166 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader,leave =True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "    outputs = model(input_ids,token_type_ids=token_type_ids,attention_mask=attention_mask,labels = labels)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loop.set_description(f'Epoch {epoch}')\n",
    "    loop.set_postfix(loss = loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17D5OPxRBo5b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BertForNextSentencePrediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
